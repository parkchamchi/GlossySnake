{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See /docs/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pstate': 'ANNOTATED', 'tokens': [{'txt': 'Les', 'is_delimiter': False, 'gloss': 'The'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'champs', 'is_delimiter': False, 'gloss': 'fields'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': \"n'étaient\", 'is_delimiter': False, 'gloss': \"weren't\"}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'point', 'is_delimiter': False, 'gloss': 'quite'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'noirs,', 'is_delimiter': False, 'gloss': 'black,'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'les', 'is_delimiter': False, 'gloss': 'the'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'cieux', 'is_delimiter': False, 'gloss': 'heavens'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': \"n'étaient\", 'is_delimiter': False, 'gloss': \"weren't\"}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'pas', 'is_delimiter': False, 'gloss': 'not'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'mornes.', 'is_delimiter': False, 'gloss': 'dull.'}, {'txt': '\\n', 'is_delimiter': True, 'gloss': None}, {'txt': 'Non,', 'is_delimiter': False, 'gloss': 'No,'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'le', 'is_delimiter': False, 'gloss': 'the'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'jour', 'is_delimiter': False, 'gloss': 'day'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'rayonnait', 'is_delimiter': False, 'gloss': 'shone'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'dans', 'is_delimiter': False, 'gloss': 'in'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'un', 'is_delimiter': False, 'gloss': 'an'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'azur', 'is_delimiter': False, 'gloss': 'azure'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'sans', 'is_delimiter': False, 'gloss': 'without'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'bornes', 'is_delimiter': False, 'gloss': 'bounds'}, {'txt': '\\n', 'is_delimiter': True, 'gloss': None}, {'txt': 'Sur', 'is_delimiter': False, 'gloss': 'Upon'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'la', 'is_delimiter': False, 'gloss': 'the'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'terre', 'is_delimiter': False, 'gloss': 'earth'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'étendu,', 'is_delimiter': False, 'gloss': 'extended,'}, {'txt': '\\n', 'is_delimiter': True, 'gloss': None}, {'txt': \"L'air\", 'is_delimiter': False, 'gloss': 'The-air'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'était', 'is_delimiter': False, 'gloss': 'was'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'plein', 'is_delimiter': False, 'gloss': 'full'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': \"d'encens\", 'is_delimiter': False, 'gloss': 'of-encense'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'et', 'is_delimiter': False, 'gloss': 'and'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'les', 'is_delimiter': False, 'gloss': 'the'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'prés', 'is_delimiter': False, 'gloss': 'meadows'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'de', 'is_delimiter': False, 'gloss': 'of'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'verdures', 'is_delimiter': False, 'gloss': 'greennesses'}, {'txt': '\\n', 'is_delimiter': True, 'gloss': None}, {'txt': 'Quand', 'is_delimiter': False, 'gloss': 'When'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'il', 'is_delimiter': False, 'gloss': 'he'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'revit', 'is_delimiter': False, 'gloss': 'revived'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'ces', 'is_delimiter': False, 'gloss': 'these'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'lieux', 'is_delimiter': False, 'gloss': 'places'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'où', 'is_delimiter': False, 'gloss': 'where'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'par', 'is_delimiter': False, 'gloss': 'by'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'tant', 'is_delimiter': False, 'gloss': 'so-many'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'de', 'is_delimiter': False, 'gloss': 'of'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'blessures', 'is_delimiter': False, 'gloss': 'wounds'}, {'txt': '\\n', 'is_delimiter': True, 'gloss': None}, {'txt': 'Son', 'is_delimiter': False, 'gloss': 'His'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'coeur', 'is_delimiter': False, 'gloss': 'heart'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': \"s'est\", 'is_delimiter': False, 'gloss': 'has'}, {'txt': ' ', 'is_delimiter': True, 'gloss': None}, {'txt': 'répandu!', 'is_delimiter': False, 'gloss': 'diffused!'}], 'is_delimiter': False, 'token_delimiters': ' \\t\\n\\r\\x0b\\x0c', 'annotator_info': 'ChatGptAnnotator_`French`_`English`', 'original_text': \"Les champs n'étaient point noirs, les cieux n'étaient pas mornes.\\nNon, le jour rayonnait dans un azur sans bornes\\nSur la terre étendu,\\nL'air était plein d'encens et les prés de verdures\\nQuand il revit ces lieux où par tant de blessures\\nSon coeur s'est répandu!\", 'annotator_info_obj': {'annotator_name': 'chatgpt_ft0', 'lang_from': 'French', 'lang_to': 'English'}}\n",
      "{'pstate': 'PARSED', 'tokens': [{'txt': '\\n\\n', 'is_delimiter': True, 'gloss': None}], 'is_delimiter': True, 'token_delimiters': ' \\t\\n\\r\\x0b\\x0c', 'annotator_info': '', 'original_text': '\\n\\n', 'annotator_info_obj': {'annotator_name': None, 'lang_from': None, 'lang_to': None}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "v4_filename = \"Tristesse d'Olympio.corpus.json\"\n",
    "with open(v4_filename, \"rt\", encoding=\"utf-8\") as fin:\n",
    "\tv4 = json.load(fin)\n",
    "\n",
    "ps = v4[\"paragraphs\"]\n",
    "for p in ps[:2]:\n",
    "\tprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive\n",
    "import uuid\n",
    "\n",
    "title = v4_filename.replace(\".corpus.json\", \"\")\n",
    "author = \"Victor Hugo\"\n",
    "annotation_info = \"Machine-glossed with fine-tuned gpt-4o-mini (https://github.com/parkchamchi/GlossySnake/blob/master/src/tools/data/gs_240918.jsonl)\"\n",
    "original_language = \"fr\"\n",
    "gloss_language = \"en\"\n",
    "note = \"Initially generated as a v4 file.\"\n",
    "unique_identifier = uuid.uuid4().int\n",
    "\n",
    "p_out_s = []\n",
    "gs_out_s = []\n",
    "for p_id, p in enumerate(v4[\"paragraphs\"]):\n",
    "\tp_out = \"\"\n",
    "\tg_out_s = []\n",
    "\tfor t_id, t in enumerate(p[\"tokens\"]):\n",
    "\t\tt_out = t[\"txt\"]\n",
    "\t\tis_delimiter = t[\"is_delimiter\"]\n",
    "\t\tif not is_delimiter:\n",
    "\t\t\tt_out = f\"<token id='{ t_id }'>{ t_out }</token>\" \n",
    "\n",
    "\t\t\tg_out = t[\"gloss\"]\n",
    "\t\t\tspecial = \"\"\n",
    "\t\t\tif g_out == \"!UNKNOWN\":\n",
    "\t\t\t\tspecial = \" special='unknown'\"\n",
    "\t\t\telif g_out == \"!TO_REANNOTATE\":\n",
    "\t\t\t\tspecial = \" special='to-reannotate'\"\n",
    "\t\t\tg_out = f\"<gloss-for-token for='{ t_id }'{ special }>{ g_out }</gloss-for-token>\"\n",
    "\t\t\tg_out_s.append(g_out)\n",
    "\t\tp_out += t_out\n",
    "\n",
    "\tp_out = f\"<paragraph id='{ p_id }'>{ p_out }</paragraph>\"\n",
    "\tp_out_s.append(p_out)\n",
    "\n",
    "\tif g_out_s != []:\n",
    "\t\tgs_out = ''.join(g_out_s)\n",
    "\t\tgs_out = f\"<glosses-for-paragraph for='{ p_id }'>{ gs_out }</glosses-for-paragraph>\"\n",
    "\t\tgs_out_s.append(gs_out)\n",
    "\t\n",
    "newline = '\\n\\t'\n",
    "out = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<glossysnake-text version=\"5\">\n",
    "\t<metadata>\n",
    "\t\t<item type=\"title\">{ title }</item>\n",
    "\t\t<item type=\"author\">{ author }</item>\n",
    "\t\t<item type=\"annotation-info\">{ annotation_info }</item>\n",
    "\t\t<item type=\"original-language\">{ original_language }</item>\n",
    "\t\t<item type=\"gloss-language\">{ gloss_language }</item>\n",
    "\t\t<item type=\"note\">{ note }</item>\n",
    "\t\t<item type=\"unique-identifier\">{ unique_identifier }</item>\n",
    "\t</metadata>\n",
    "\n",
    "\t<paragraphs>{ ''.join(p_out_s) }</paragraphs>\n",
    "\n",
    "\t<glosses>\n",
    "\t\t{ newline.join(gs_out_s) }\n",
    "\t</glosses>\n",
    "</glossysnake-text>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(v4_filename.replace(\".json\", \".xml\"), \"wt\", encoding=\"utf-8\") as fout:\n",
    "\tfout.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
