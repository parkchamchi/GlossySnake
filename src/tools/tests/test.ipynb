{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.11.2에 연결됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "\n",
    "HOST = \"http://127.0.0.1:56123\"\n",
    "\n",
    "REGISTRATION_URL = f\"{HOST}/api/v4/rest-auth/registration/\"\n",
    "LOGIN_URL = f\"{HOST}/api/v4/rest-auth/login/\"\n",
    "LOGOUT_URL = f\"{HOST}/api/v4/rest-auth/logout/\"\n",
    "UPLOAD_URL = f\"{HOST}/api/v4/upload\"\n",
    "DIVIDE_URL = f\"{HOST}/api/v4/parser/divide\"\n",
    "PARSE_URL = f\"{HOST}/api/v4/parser/parse\"\n",
    "ANNOTATE_URL = f\"{HOST}/api/v4/annotator/annotate\"\n",
    "CORPUSES_URL = f\"{HOST}/api/v4/corpuses/\"\n",
    "\n",
    "url = \"http://127.0.0.1:56123\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_membership = {\n",
    "    \"username\": \"abc111\",\n",
    "    \"email\": \"abcdefghi12@naver.com\",\n",
    "    \"password1\": \"testaaaaaa!\",\n",
    "    \"password2\": \"testaaaaaa!\"\n",
    "}\n",
    "\n",
    "join_membership_response = requests.post(REGISTRATION_URL, data=join_membership)\n",
    "\n",
    "login = {\n",
    "    \"username\": \"abc111\",\n",
    "    \"email\": \"abcdefghi12@naver.com\",\n",
    "    \"password\": \"testaaaaaa!\"\n",
    "}\n",
    "\n",
    "login_response= requests.post(LOGIN_URL, json=login)\n",
    "login_data = login_response.json()\n",
    "token = login_data.get('key')\n",
    "\n",
    "login_key = {\n",
    "    'Authorization': f'Token {token}'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    {\"original_text\": \"Die Alpen erstrecken sich über mehrere Länder Europas ...\"},\n",
    "    {\"original_text\": \"Der Rhein ist einer der längsten Flüsse Europas ...\"},\n",
    "    {\"original_text\": \"München, bekannt für das Oktoberfest ...\"},\n",
    "    {\"original_text\": \"Der Schwarzwald ist ein großes Waldgebiet ...\"},\n",
    "    {\"original_text\": \"Die Insel Rügen ist die größte Insel Deutschlands ...\"},\n",
    "    {\"original_text\": \"Die Wartburg, eine mittelalterliche Burg in Thüringen ...\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt_ft0\n",
      "2.73698 sec\n",
      "chatgpt_ft0\n",
      "1.26771 sec\n",
      "chatgpt_ft0\n",
      "1.07898 sec\n",
      "chatgpt_ft0\n",
      "1.35017 sec\n",
      "chatgpt_ft0\n",
      "1.44054 sec\n",
      "chatgpt_ft0\n",
      "1.24414 sec\n",
      "dummy\n",
      "0.12476 sec\n",
      "dummy\n",
      "0.15148 sec\n",
      "dummy\n",
      "0.15495 sec\n",
      "dummy\n",
      "0.26533 sec\n",
      "dummy\n",
      "0.17129 sec\n",
      "dummy\n",
      "0.20500 sec\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "annotate_list = []\n",
    "annotators = [\"chatgpt_ft0\", \"dummy\"]\n",
    "\n",
    "for annotator_name in annotators:\n",
    "    for text in texts:\n",
    "        upload_response = requests.post(UPLOAD_URL, json=text, headers=login_key)\n",
    "        corpus_id = upload_response.json().get('corpus_id')\n",
    "\n",
    "        divide_data = {\n",
    "            \"corpus_id\": corpus_id,\n",
    "            \"divide_options\": json.dumps({\"p_delims\": [\"\\n\"]})\n",
    "        }\n",
    "        divide_response = requests.post(DIVIDE_URL, json=divide_data, headers=login_key)\n",
    "\n",
    "        parse_data = {\n",
    "            \"corpus_id\": corpus_id,\n",
    "            \"parse_options\": json.dumps({\"t_delims\": \" \\t\\n\\r\\u000b\\f\"})\n",
    "        }\n",
    "        parse_response = requests.post(PARSE_URL, json=parse_data, headers=login_key)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        annotate_data = {\n",
    "            \"corpus_id\": corpus_id,\n",
    "            \"annotate_options\": json.dumps({\n",
    "                \"lang_from\": \"German\",\n",
    "                \"lang_to\": \"English\",\n",
    "                \"annotator_name\": annotator_name\n",
    "            })\n",
    "        }\n",
    "        annotate_response = requests.post(ANNOTATE_URL, json=annotate_data, headers=login_key)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(annotator_name)\n",
    "        print(f\"{end - start:.5f} sec\")\n",
    "        time_list.append(end - start)\n",
    "        annotate_list.append(annotator_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotator_name: chatgpt_ft0 time: 2.74 , return_rate: 100.0\n",
      "1 annotator_name: chatgpt_ft0 time: 1.27 , return_rate: 100.0\n",
      "2 annotator_name: chatgpt_ft0 time: 1.08 , return_rate: 100.0\n",
      "3 annotator_name: chatgpt_ft0 time: 1.35 , return_rate: 100.0\n",
      "4 annotator_name: chatgpt_ft0 time: 1.44 , return_rate: 100.0\n",
      "5 annotator_name: chatgpt_ft0 time: 1.24 , return_rate: 100.0\n",
      "6 annotator_name: dummy time: 0.12 , return_rate: 100.0\n",
      "7 annotator_name: dummy time: 0.15 , return_rate: 100.0\n",
      "8 annotator_name: dummy time: 0.15 , return_rate: 100.0\n",
      "9 annotator_name: dummy time: 0.27 , return_rate: 100.0\n",
      "10 annotator_name: dummy time: 0.17 , return_rate: 100.0\n",
      "11 annotator_name: dummy time: 0.2 , return_rate: 100.0\n"
     ]
    }
   ],
   "source": [
    "corpuses_respons = requests.get(CORPUSES_URL, headers=login_key)\n",
    "corpuse_history = corpuses_respons.json()\n",
    "\n",
    "start = len(texts)\n",
    "num = int(corpuse_history[-1].get('corpus_id'))  # 마지막 코퍼스의 ID 가져오기\n",
    "\n",
    "for number in range(num):\n",
    "    Unknown_count = 0\n",
    "    token_sum = 0\n",
    "    for corpus_record in corpuse_history[number]['corpuses_history']:\n",
    "        for paragraph in corpus_record['paragraphs']:\n",
    "            if paragraph['pstate'] == \"ANNOTATED\":\n",
    "                for token in paragraph.get('tokens', []):\n",
    "                    if not token['is_delimiter']:\n",
    "                        token_sum += 1\n",
    "                        if token.get('gloss') == \"!UNKNOWN\":\n",
    "                            Unknown_count += 1\n",
    "                            print(token)\n",
    "\n",
    "    if token_sum > 0:\n",
    "        Return_rate = ((token_sum - Unknown_count) / token_sum) * 100\n",
    "        print(number, \"annotator_name:\", annotate_list[number], \"time:\", round(float(time_list[number]), 2), \", return_rate:\", round(Return_rate, 2))\n",
    "    else:\n",
    "        print(number, \"time:\", round(float(time_list[number]), 2), \", No tokens to calculate return rate\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
